{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqnIOf1oB2r9"
      },
      "source": [
        "# Entraînement d'un réseau de neurones pour jouer au Go\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/auduvignac/Deep-learning/blob/main/Projet/importGolois2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGW-Bl5SB2r_"
      },
      "source": [
        "## Description\n",
        "\n",
        "- [https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html](https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html)  \n",
        "- L'objectif est d'entraîner un réseau pour jouer au jeu de Go.  \n",
        "- Afin de garantir une équité en termes de ressources d'entraînement, le nombre de paramètres des réseaux soumis doit être inférieur à 100 000.  \n",
        "- Le nombre maximal d'étudiants par équipe est de deux.  \n",
        "- Les données utilisées pour l'entraînement proviennent des parties auto-jouées du programme Katago Go.  \n",
        "- Le jeu de données d'entraînement contient un total de 1 000 000 de parties différentes.  \n",
        "- Les données d'entrée sont composées de 31 plans de taille 19x19 :  \n",
        "  - Couleur au trait  \n",
        "  - Échelles  \n",
        "  - État actuel sur deux plans  \n",
        "  - Deux états précédents sur plusieurs plans  \n",
        "- Les cibles de sortie sont :  \n",
        "  - **La politique** : un vecteur de taille 361 avec `1.0` pour le coup joué, `0.0` pour les autres coups.  \n",
        "  - **La valeur** : une valeur entre `0.0` et `1.0` fournie par la recherche d'arbre Monte-Carlo, représentant la probabilité de victoire de Blanc.\n",
        "\n",
        "- Le projet a été écrit et fonctionne sous Ubuntu 22.04.  \n",
        "- Il utilise TensorFlow 2.9 et Keras pour le réseau.  \n",
        "- Un exemple de réseau convolutionnel avec deux têtes est donné dans le fichier `golois.py` et est sauvegardé dans le fichier `test.h5`.  \n",
        "- Les réseaux que vous concevez et entraînez doivent également avoir les mêmes têtes de politique et de valeur et être sauvegardés au format `.h5`.  \n",
        "- Un exemple de réseau et un épisode d'entraînement sont fournis dans le fichier `golois.py`.  \n",
        "- Si vous souhaitez compiler la bibliothèque Golois, vous devez installer **Pybind11** et exécuter `compile.sh`.\n",
        "\n",
        "## Tournois\n",
        "\n",
        "- Toutes les deux semaines environ, j'organiserai un tournoi entre les réseaux que vous téléchargez.  \n",
        "- Chaque nom de réseau correspond aux noms des étudiants qui ont conçu et entraîné le réseau.  \n",
        "- Le modèle doit être sauvegardé au format **Keras h5**.  \n",
        "- Un tournoi en **round robin** sera organisé et les résultats seront envoyés par e-mail.  \n",
        "- Chaque réseau sera utilisé par un moteur **PUCT**, qui disposera de **2 secondes de temps CPU** par coup pour jouer dans le tournoi.\n",
        "\n",
        "## Exemple de réseau\n",
        "\n",
        "```python\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "epochs = 20\n",
        "batch = 128\n",
        "filters = 32\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "\n",
        "input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input)\n",
        "for i in range (5):\n",
        "  x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "policy_head = layers.Flatten()(policy_head)\n",
        "policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "value_head = layers.Flatten()(value_head)\n",
        "value_head = layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "for i in range (1, epochs + 1):\n",
        "  print ('epoch ' + str (i))\n",
        "  golois.getBatch (input_data, policy, value, end, groups, i * N)\n",
        "  history = model.fit(input_data,\n",
        "  {'policy': policy, 'value': value},\n",
        "  epochs=1, batch_size=batch)\n",
        "  if (i % 5 == 0):\n",
        "  gc.collect ()\n",
        "  if (i % 20 == 0):\n",
        "  golois.getValidation (input_data, policy, value, end)\n",
        "  val = model.evaluate (input_data,\n",
        "  [policy, value], verbose = 0, batch_size=batch)\n",
        "  print (\"val =\", val)\n",
        "  model.save ('test.h5')\n",
        "```\n",
        "\n",
        "## Instructions :  \n",
        "- Entraînez un réseau pour jouer au Go.  \n",
        "- Soumettez les réseaux entraînés **avant samedi soir**.  \n",
        "- Tournoi des réseaux **chaque dimanche**.  \n",
        "- Téléchargez un réseau **avant la fin de la session**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvTcnNjdcrGe",
        "outputId": "efbf1005-6eb7-45d0-d145-276c9eb91682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-12 20:24:34--  https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
            "Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n",
            "Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 486727746 (464M) [application/zip]\n",
            "Saving to: ‘project2025.zip’\n",
            "\n",
            "project2025.zip     100%[===================>] 464.18M  4.94MB/s    in 42s     \n",
            "\n",
            "2025-03-12 20:25:18 (11.0 MB/s) - ‘project2025.zip’ saved [486727746/486727746]\n",
            "\n",
            "Archive:  project2025.zip\n",
            "  inflating: games2022.data          \n",
            "  inflating: Golois.cpython-310-x86_64-linux-gnu.so  \n",
            "  inflating: Golois.cpython-38-x86_64-linux-gnu.so  \n",
            "  inflating: golois.cpython-310-x86_64-linux-gnu.so  \n",
            "  inflating: golois.cpython-311-x86_64-linux-gnu.so  \n",
            "  inflating: golois.cpython-37m-x86_64-linux-gnu.so  \n",
            "  inflating: golois.cpython-38-x86_64-linux-gnu.so  \n",
            "  inflating: trainGolois.py          \n",
            "total 2382016\n",
            "-rw-r--r-- 1 root root 1950168720 Feb 23  2023 games2022.data\n",
            "-rwxr-xr-x 1 root root     234952 Jan 24  2024 golois.cpython-310-x86_64-linux-gnu.so\n",
            "-rwxr-xr-x 1 root root     692584 Jan 24  2024 Golois.cpython-310-x86_64-linux-gnu.so\n",
            "-rwxr-xr-x 1 root root     239144 Jul 19  2023 golois.cpython-311-x86_64-linux-gnu.so\n",
            "-rwxr-xr-x 1 root root     236328 Oct  7  2022 golois.cpython-37m-x86_64-linux-gnu.so\n",
            "-rwxr-xr-x 1 root root     202584 Mar 19  2023 golois.cpython-38-x86_64-linux-gnu.so\n",
            "-rwxr-xr-x 1 root root     644840 Aug  5  2023 Golois.cpython-38-x86_64-linux-gnu.so\n",
            "-rw-r--r-- 1 root root  486727746 Jan 22 14:37 project2025.zip\n",
            "drwxr-xr-x 1 root root       4096 Mar 11 13:29 sample_data\n",
            "-rw-r--r-- 1 root root       2621 Jan 22 14:24 trainGolois.py\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
        "!unzip project2025.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXj_yFKDbhiI",
        "outputId": "fca1c271-950f-40ac-98eb-a438d5972e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt-bindings==8.6.1\n",
            "  Downloading tensorrt_bindings-8.6.1-cp311-none-manylinux_2_17_x86_64.whl.metadata (621 bytes)\n",
            "Downloading tensorrt_bindings-8.6.1-cp311-none-manylinux_2_17_x86_64.whl (980 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/980.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/980.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.8/980.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorrt-bindings\n",
            "Successfully installed tensorrt-bindings-8.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting tensorrt-libs\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-libs/tensorrt_libs-8.6.1-py2.py3-none-manylinux_2_17_x86_64.whl (824.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt-libs) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt-libs) (9.3.0.75)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt-libs) (12.5.3.2)\n",
            "Installing collected packages: tensorrt-libs\n",
            "Successfully installed tensorrt-libs-8.6.1\n",
            "Collecting tensorflow==2.15.0 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (1.70.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting nvidia-cublas-cu12==12.2.5.6 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.2.142 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvcc-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.4.25 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.8.103 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.3.141 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.5.2.141 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.2.141 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.16.5 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.2.140 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tensorrt==8.6.1.post1 (from tensorflow[and-cuda]==2.15.0)\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorrt-bindings==8.6.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]==2.15.0) (8.6.1)\n",
            "Requirement already satisfied: tensorrt-libs==8.6.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]==2.15.0) (8.6.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->tensorflow[and-cuda]==2.15.0) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl (417.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.8/417.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl (13.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (23.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.8/845.8 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.1/720.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl (98.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl (124.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl (195.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.3/195.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17284 sha256=28b8654d57e05f7419fe474b9d73f0b459455e22d4b6af7250dd552925d0613a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/5b/18/c1a34e8188001fdb6b01210ada97b0860f7b4fb88b9bbb75d7\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: wrapt, tensorrt, tensorflow-estimator, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, keras, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvcc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorstore 0.1.72 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.2.5.6 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.2.142 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.2.140 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.2.140 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 8.9.4.25 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.0.8.103 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.3.141 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.5.2.141 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.1.2.141 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.16.5 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.2.140 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 nvidia-cublas-cu12-12.2.5.6 nvidia-cuda-cupti-cu12-12.2.142 nvidia-cuda-nvcc-cu12-12.2.140 nvidia-cuda-nvrtc-cu12-12.2.140 nvidia-cuda-runtime-cu12-12.2.140 nvidia-cudnn-cu12-8.9.4.25 nvidia-cufft-cu12-11.0.8.103 nvidia-curand-cu12-10.3.3.141 nvidia-cusolver-cu12-11.5.2.141 nvidia-cusparse-cu12-12.1.2.141 nvidia-nccl-cu12-2.16.5 nvidia-nvjitlink-cu12-12.2.140 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorrt-8.6.1.post1 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorrt-bindings==8.6.1\n",
        "!pip install --extra-index-url https://pypi.nvidia.com tensorrt-libs\n",
        "!pip install tensorflow[and-cuda]==2.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9_6C3MiaVelc"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import gc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import golois\n",
        "\n",
        "class GONet():\n",
        "\n",
        "  def __init__(self, batch = 128, epochs = 20, filters = 32, moves = 361, N = 10000, planes = 31):\n",
        "    self.batch = batch\n",
        "    self.epochs = epochs\n",
        "    self.filters = filters\n",
        "    self.moves = moves\n",
        "    self.N = N\n",
        "    self.planes = planes\n",
        "    self.set_input_data(N, planes)\n",
        "    self.set_policy(N, moves)\n",
        "    self.set_value(N)\n",
        "    self.set_end(N)\n",
        "    self.set_groups(N)\n",
        "    print (\"Tensorflow version\", tf.__version__)\n",
        "    print (\"getValidation\", flush = True)\n",
        "    golois.getValidation (self.input_data, self.policy, self.value, self.end)\n",
        "\n",
        "  def set_input_data(self, N, planes):\n",
        "    input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "    self.input_data = input_data.astype ('float32')\n",
        "\n",
        "  def get_input_data(self):\n",
        "    return self.input_data\n",
        "\n",
        "  def set_policy(self, N, moves):\n",
        "    policy = np.random.randint(moves, size=(N,))\n",
        "    self.policy = keras.utils.to_categorical (policy)\n",
        "\n",
        "  def get_policy(self):\n",
        "    return self.policy\n",
        "\n",
        "  def set_value(self, N):\n",
        "    value = np.random.randint(2, size=(N,))\n",
        "    self.value = value.astype ('float32')\n",
        "\n",
        "  def get_value(self):\n",
        "    return self.value\n",
        "\n",
        "  def set_end(self, N):\n",
        "    end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "    self.end = end.astype ('float32')\n",
        "\n",
        "  def get_end(self):\n",
        "    return self.end\n",
        "\n",
        "  def set_groups(self, N):\n",
        "    groups = np.zeros((N, 19, 19, 1))\n",
        "    self.groups = groups.astype ('float32')\n",
        "\n",
        "  def get_groups(self):\n",
        "    return self.groups\n",
        "\n",
        "  def set_model(self):\n",
        "    input_ = keras.Input(shape=(19, 19, self.planes), name='board')\n",
        "    x = layers.Conv2D(self.filters, 1, activation='relu', padding='same')(input_)\n",
        "    for _ in range (5):\n",
        "        x = layers.Conv2D(self.filters, 3, activation='relu', padding='same')(x)\n",
        "    policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    policy_head = layers.Flatten()(policy_head)\n",
        "    policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "    value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    value_head = layers.Flatten()(value_head)\n",
        "    value_head = layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "    value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "\n",
        "    model = keras.Model(inputs=input_, outputs=[policy_head, value_head])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "                  loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                  loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "                  metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "\n",
        "    self.model = model\n",
        "\n",
        "  def train_model(self, epochs):\n",
        "    for i in range (1, epochs + 1):\n",
        "        print(f'epoch {str(i)}')\n",
        "        golois.getBatch(self.input_data, self.policy, self.value, self.end, self.groups, i * self.N)\n",
        "        history = self.model.fit( self.input_data,\n",
        "                                  {'policy': self.policy, 'value': self.value},\n",
        "                                  epochs=1,\n",
        "                                  batch_size=self.batch\n",
        "                                )\n",
        "        if (i % 5 == 0):\n",
        "            gc.collect ()\n",
        "        if (i % 20 == 0):\n",
        "            golois.getValidation (self.input_data, self.policy, self.value, self.end)\n",
        "            val = self.model.evaluate (self.input_data,\n",
        "                                  [self.policy, self.value], verbose = 0, batch_size=self.batch)\n",
        "            print(f\"{val=}\")\n",
        "\n",
        "  def save_model(self, name):\n",
        "    self.model.save(name)\n",
        "    files.download(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CVZ_rb1QVelh",
        "outputId": "252db308-4834-4436-b846-e541c4877a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n",
            "getValidation\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " board (InputLayer)          [(None, 19, 19, 31)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 19, 19, 32)           1024      ['board[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 19, 19, 32)           9248      ['conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 19, 19, 32)           9248      ['conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 19, 19, 32)           9248      ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 19, 19, 32)           9248      ['conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 19, 19, 32)           9248      ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 19, 19, 1)            32        ['conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 19, 19, 1)            32        ['conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 361)                  0         ['conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 361)                  0         ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 50)                   18100     ['flatten_5[0][0]']           \n",
            "                                                                                                  \n",
            " policy (Activation)         (None, 361)                  0         ['flatten_4[0][0]']           \n",
            "                                                                                                  \n",
            " value (Dense)               (None, 1)                    51        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 65479 (255.78 KB)\n",
            "Trainable params: 65479 (255.78 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "epoch 1\n",
            "79/79 [==============================] - 3s 13ms/step - loss: 6.5895 - policy_loss: 5.8870 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0018 - value_mse: 0.1197\n",
            "epoch 2\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 6.5841 - policy_loss: 5.8816 - value_loss: 0.6930 - policy_categorical_accuracy: 0.0034 - value_mse: 0.1213\n",
            "epoch 3\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 6.5761 - policy_loss: 5.8736 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0064 - value_mse: 0.1209\n",
            "epoch 4\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 6.5634 - policy_loss: 5.8613 - value_loss: 0.6927 - policy_categorical_accuracy: 0.0104 - value_mse: 0.1213\n",
            "epoch 5\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 6.5415 - policy_loss: 5.8389 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0101 - value_mse: 0.1216\n",
            "epoch 6\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 6.4932 - policy_loss: 5.7910 - value_loss: 0.6927 - policy_categorical_accuracy: 0.0115 - value_mse: 0.1218\n",
            "epoch 7\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 6.3946 - policy_loss: 5.6923 - value_loss: 0.6929 - policy_categorical_accuracy: 0.0111 - value_mse: 0.1215\n",
            "epoch 8\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 6.2298 - policy_loss: 5.5270 - value_loss: 0.6933 - policy_categorical_accuracy: 0.0117 - value_mse: 0.1210\n",
            "epoch 9\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 6.0418 - policy_loss: 5.3393 - value_loss: 0.6930 - policy_categorical_accuracy: 0.0147 - value_mse: 0.1211\n",
            "epoch 10\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 5.8733 - policy_loss: 5.1710 - value_loss: 0.6929 - policy_categorical_accuracy: 0.0197 - value_mse: 0.1244\n",
            "epoch 11\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 5.7443 - policy_loss: 5.0420 - value_loss: 0.6928 - policy_categorical_accuracy: 0.0335 - value_mse: 0.1207\n",
            "epoch 12\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 5.5804 - policy_loss: 4.8778 - value_loss: 0.6930 - policy_categorical_accuracy: 0.0502 - value_mse: 0.1212\n",
            "epoch 13\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 5.2876 - policy_loss: 4.5851 - value_loss: 0.6930 - policy_categorical_accuracy: 0.0858 - value_mse: 0.1205\n",
            "epoch 14\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 5.0737 - policy_loss: 4.3712 - value_loss: 0.6929 - policy_categorical_accuracy: 0.1150 - value_mse: 0.1204\n",
            "epoch 15\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 4.9811 - policy_loss: 4.2786 - value_loss: 0.6930 - policy_categorical_accuracy: 0.1193 - value_mse: 0.1219\n",
            "epoch 16\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 4.8669 - policy_loss: 4.1644 - value_loss: 0.6929 - policy_categorical_accuracy: 0.1379 - value_mse: 0.1227\n",
            "epoch 17\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 4.8393 - policy_loss: 4.1369 - value_loss: 0.6929 - policy_categorical_accuracy: 0.1426 - value_mse: 0.1215\n",
            "epoch 18\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 4.7994 - policy_loss: 4.0970 - value_loss: 0.6929 - policy_categorical_accuracy: 0.1515 - value_mse: 0.1211\n",
            "epoch 19\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 4.7624 - policy_loss: 4.0597 - value_loss: 0.6932 - policy_categorical_accuracy: 0.1552 - value_mse: 0.1202\n",
            "epoch 20\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 4.7269 - policy_loss: 4.0242 - value_loss: 0.6931 - policy_categorical_accuracy: 0.1616 - value_mse: 0.1212\n",
            "val=[4.741727828979492, 4.039369106292725, 0.6928429007530212, 0.16419999301433563, 0.12031660228967667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8de888a-ef82-4876-8f9b-fb507b50fbfa\", \"test.h5\", 596760)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "GONet_instance = GONet()\n",
        "GONet_instance.set_model()\n",
        "GONet_instance.train_model(20)\n",
        "GONet_instance.save_model('test.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iqGFjAejB2sH"
      },
      "outputs": [],
      "source": [
        "class GONetResidual(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    # Residual Block Function\n",
        "    def residual_block(self, x, filters):\n",
        "        \"\"\"A ResNet-style residual block with skip connection.\"\"\"\n",
        "        shortcut = x  # Save input for shortcut connection\n",
        "\n",
        "        x = layers.Conv2D(filters, (3, 3), padding='same', use_bias=False,\n",
        "                          kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Add()([x, shortcut])  # Add residual connection\n",
        "        x = layers.ReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_model(self):\n",
        "        input_layer = layers.Input(shape=(19, 19, self.planes), name=\"board\")\n",
        "        # Initial Conv Layer\n",
        "        x = layers.Conv2D(\n",
        "            self.filters,\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(input_layer)\n",
        "        # Apply 2 Residual Blocks\n",
        "        for _ in range(2):\n",
        "            x = self.residual_block(x, self.filters)\n",
        "\n",
        "        # Policy Head (Move Probabilities)\n",
        "        policy_head = layers.Conv2D(\n",
        "            2,\n",
        "            (1, 1),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Dense(\n",
        "            361,\n",
        "            activation=\"softmax\",\n",
        "            name=\"policy\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(policy_head)\n",
        "\n",
        "        # Value Head (Win Probability)\n",
        "        value_head = layers.Conv2D(\n",
        "            1,\n",
        "            (1, 1),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        "        )(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            1,\n",
        "            activation=\"sigmoid\",\n",
        "            name=\"value\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(value_head)\n",
        "\n",
        "        # Create Model\n",
        "        model = keras.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.summary()\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "            loss={\n",
        "                \"policy\": \"categorical_crossentropy\",\n",
        "                \"value\": \"binary_crossentropy\",\n",
        "            },\n",
        "            loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "            metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "        )\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GONetResidual_instance = GONetResidual()\n",
        "GONetResidual_instance.set_model()\n",
        "GONetResidual_instance.train_model(20)\n",
        "GONetResidual_instance.save_model('test.h5')"
      ],
      "metadata": {
        "id": "D8IbBVJtEj-_",
        "outputId": "3514d465-fd5b-486b-e3ca-f3a6ec0c84d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n",
            "getValidation\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " board (InputLayer)          [(None, 19, 19, 31)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 19, 19, 32)           8960      ['board[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 19, 19, 32)           9216      ['conv2d_24[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 19, 19, 32)           128       ['conv2d_25[0][0]']           \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 19, 19, 32)           0         ['batch_normalization[0][0]', \n",
            "                                                                     'conv2d_24[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 19, 19, 32)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 19, 19, 32)           9216      ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 19, 19, 32)           128       ['conv2d_26[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 19, 19, 32)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    , 're_lu[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 19, 19, 32)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 19, 19, 1)            32        ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 19, 19, 2)            64        ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)         (None, 361)                  0         ['conv2d_28[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)         (None, 722)                  0         ['conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 50)                   18100     ['flatten_7[0][0]']           \n",
            "                                                                                                  \n",
            " policy (Dense)              (None, 361)                  261003    ['flatten_6[0][0]']           \n",
            "                                                                                                  \n",
            " value (Dense)               (None, 1)                    51        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 306898 (1.17 MB)\n",
            "Trainable params: 306770 (1.17 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "epoch 1\n",
            "79/79 [==============================] - 3s 12ms/step - loss: 6.8133 - policy_loss: 6.0099 - value_loss: 0.7360 - policy_categorical_accuracy: 0.0034 - value_mse: 0.1374\n",
            "epoch 2\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 6.6799 - policy_loss: 5.9030 - value_loss: 0.7096 - policy_categorical_accuracy: 0.0025 - value_mse: 0.1290\n",
            "epoch 3\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 6.6612 - policy_loss: 5.8950 - value_loss: 0.6990 - policy_categorical_accuracy: 0.0028 - value_mse: 0.1237\n",
            "epoch 4\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6568 - policy_loss: 5.8911 - value_loss: 0.6984 - policy_categorical_accuracy: 0.0037 - value_mse: 0.1241\n",
            "epoch 5\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6558 - policy_loss: 5.8923 - value_loss: 0.6963 - policy_categorical_accuracy: 0.0017 - value_mse: 0.1231\n",
            "epoch 6\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6518 - policy_loss: 5.8909 - value_loss: 0.6936 - policy_categorical_accuracy: 0.0025 - value_mse: 0.1222\n",
            "epoch 7\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6500 - policy_loss: 5.8898 - value_loss: 0.6929 - policy_categorical_accuracy: 0.0022 - value_mse: 0.1215\n",
            "epoch 8\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6500 - policy_loss: 5.8899 - value_loss: 0.6930 - policy_categorical_accuracy: 0.0029 - value_mse: 0.1209\n",
            "epoch 9\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6493 - policy_loss: 5.8897 - value_loss: 0.6925 - policy_categorical_accuracy: 0.0034 - value_mse: 0.1208\n",
            "epoch 10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 6.6483 - policy_loss: 5.8890 - value_loss: 0.6922 - policy_categorical_accuracy: 0.0028 - value_mse: 0.1240\n",
            "epoch 11\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6475 - policy_loss: 5.8897 - value_loss: 0.6907 - policy_categorical_accuracy: 0.0019 - value_mse: 0.1196\n",
            "epoch 12\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6482 - policy_loss: 5.8895 - value_loss: 0.6916 - policy_categorical_accuracy: 0.0023 - value_mse: 0.1205\n",
            "epoch 13\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 6.6474 - policy_loss: 5.8888 - value_loss: 0.6914 - policy_categorical_accuracy: 0.0026 - value_mse: 0.1197\n",
            "epoch 14\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 6.6471 - policy_loss: 5.8890 - value_loss: 0.6910 - policy_categorical_accuracy: 0.0031 - value_mse: 0.1194\n",
            "epoch 15\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6476 - policy_loss: 5.8896 - value_loss: 0.6909 - policy_categorical_accuracy: 0.0025 - value_mse: 0.1209\n",
            "epoch 16\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 6.6460 - policy_loss: 5.8887 - value_loss: 0.6902 - policy_categorical_accuracy: 0.0023 - value_mse: 0.1213\n",
            "epoch 17\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 6.6468 - policy_loss: 5.8891 - value_loss: 0.6906 - policy_categorical_accuracy: 0.0025 - value_mse: 0.1203\n",
            "epoch 18\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 6.6455 - policy_loss: 5.8883 - value_loss: 0.6902 - policy_categorical_accuracy: 0.0031 - value_mse: 0.1198\n",
            "epoch 19\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 6.6466 - policy_loss: 5.8891 - value_loss: 0.6904 - policy_categorical_accuracy: 0.0031 - value_mse: 0.1188\n",
            "epoch 20\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 6.6461 - policy_loss: 5.8890 - value_loss: 0.6901 - policy_categorical_accuracy: 0.0023 - value_mse: 0.1197\n",
            "val=[6.64612340927124, 5.888782978057861, 0.6903101801872253, 0.003100000089034438, 0.1190517246723175]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}