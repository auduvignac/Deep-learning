{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqnIOf1oB2r9"
      },
      "source": [
        "# Entraînement d'un réseau de neurones pour jouer au Go\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/auduvignac/Deep-learning/blob/main/Projet/ResGo2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGW-Bl5SB2r_"
      },
      "source": [
        "## Description\n",
        "\n",
        "- [https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html](https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html)  \n",
        "- L'objectif est d'entraîner un réseau pour jouer au jeu de Go.  \n",
        "- Afin de garantir une équité en termes de ressources d'entraînement, le nombre de paramètres des réseaux soumis doit être inférieur à 100 000.  \n",
        "- Le nombre maximal d'étudiants par équipe est de deux.  \n",
        "- Les données utilisées pour l'entraînement proviennent des parties auto-jouées du programme Katago Go.  \n",
        "- Le jeu de données d'entraînement contient un total de 1 000 000 de parties différentes.  \n",
        "- Les données d'entrée sont composées de 31 plans de taille 19x19 :  \n",
        "  - Couleur au trait  \n",
        "  - Échelles  \n",
        "  - État actuel sur deux plans  \n",
        "  - Deux états précédents sur plusieurs plans  \n",
        "- Les cibles de sortie sont :  \n",
        "  - **La politique** : un vecteur de taille 361 avec `1.0` pour le coup joué, `0.0` pour les autres coups.  \n",
        "  - **La valeur** : une valeur entre `0.0` et `1.0` fournie par la recherche d'arbre Monte-Carlo, représentant la probabilité de victoire de Blanc.\n",
        "\n",
        "- Le projet a été écrit et fonctionne sous Ubuntu 22.04.  \n",
        "- Il utilise TensorFlow 2.9 et Keras pour le réseau.  \n",
        "- Un exemple de réseau convolutionnel avec deux têtes est donné dans le fichier `golois.py` et est sauvegardé dans le fichier `test.h5`.  \n",
        "- Les réseaux que vous concevez et entraînez doivent également avoir les mêmes têtes de politique et de valeur et être sauvegardés au format `.h5`.  \n",
        "- Un exemple de réseau et un épisode d'entraînement sont fournis dans le fichier `golois.py`.  \n",
        "- Si vous souhaitez compiler la bibliothèque Golois, vous devez installer **Pybind11** et exécuter `compile.sh`.\n",
        "\n",
        "## Tournois\n",
        "\n",
        "- Toutes les deux semaines environ, j'organiserai un tournoi entre les réseaux que vous téléchargez.  \n",
        "- Chaque nom de réseau correspond aux noms des étudiants qui ont conçu et entraîné le réseau.  \n",
        "- Le modèle doit être sauvegardé au format **Keras h5**.  \n",
        "- Un tournoi en **round robin** sera organisé et les résultats seront envoyés par e-mail.  \n",
        "- Chaque réseau sera utilisé par un moteur **PUCT**, qui disposera de **2 secondes de temps CPU** par coup pour jouer dans le tournoi.\n",
        "\n",
        "## Exemple de réseau\n",
        "\n",
        "```python\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "epochs = 20\n",
        "batch = 128\n",
        "filters = 32\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "\n",
        "input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input)\n",
        "for i in range (5):\n",
        "  x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "policy_head = layers.Flatten()(policy_head)\n",
        "policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "value_head = layers.Flatten()(value_head)\n",
        "value_head = layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "for i in range (1, epochs + 1):\n",
        "  print ('epoch ' + str (i))\n",
        "  golois.getBatch (input_data, policy, value, end, groups, i * N)\n",
        "  history = model.fit(input_data,\n",
        "  {'policy': policy, 'value': value},\n",
        "  epochs=1, batch_size=batch)\n",
        "  if (i % 5 == 0):\n",
        "  gc.collect ()\n",
        "  if (i % 20 == 0):\n",
        "  golois.getValidation (input_data, policy, value, end)\n",
        "  val = model.evaluate (input_data,\n",
        "  [policy, value], verbose = 0, batch_size=batch)\n",
        "  print (\"val =\", val)\n",
        "  model.save ('test.h5')\n",
        "```\n",
        "\n",
        "## Instructions :  \n",
        "- Entraînez un réseau pour jouer au Go.  \n",
        "- Soumettez les réseaux entraînés **avant samedi soir**.  \n",
        "- Tournoi des réseaux **chaque dimanche**.  \n",
        "- Téléchargez un réseau **avant la fin de la session**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvTcnNjdcrGe",
        "outputId": "62f18e36-ef76-4c20-8e58-64cfd8793d17"
      },
      "outputs": [],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
        "!unzip project2025.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXj_yFKDbhiI",
        "outputId": "264ca6e0-8a20-42cb-8602-4e70551470d9"
      },
      "outputs": [],
      "source": [
        "!pip install tensorrt-bindings==8.6.1\n",
        "!pip install --extra-index-url https://pypi.nvidia.com tensorrt-libs\n",
        "!pip install tensorflow[and-cuda]==2.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_6C3MiaVelc"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from google.colab import files\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "\n",
        "import golois\n",
        "\n",
        "\n",
        "class GONet(ABC):\n",
        "\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        self.batch = batch\n",
        "        self.epochs = epochs\n",
        "        self.filters = filters\n",
        "        self.moves = moves\n",
        "        self.N = N\n",
        "        self.planes = planes\n",
        "        self.set_input_data(N, planes)\n",
        "        self.set_policy(N, moves)\n",
        "        self.set_value(N)\n",
        "        self.set_end(N)\n",
        "        self.set_groups(N)\n",
        "        print(\"Tensorflow version\", tf.__version__)\n",
        "        print(\"getValidation\", flush=True)\n",
        "        golois.getValidation(\n",
        "            self.input_data, self.policy, self.value, self.end\n",
        "        )\n",
        "        self.loss_total = []\n",
        "        self.policy_loss  = []\n",
        "        self.value_loss  = []\n",
        "        self.policy_acc = []\n",
        "        self.value_mse = []\n",
        "\n",
        "    def set_input_data(self, N, planes):\n",
        "        input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "        self.input_data = input_data.astype(\"float32\")\n",
        "\n",
        "    def get_input_data(self):\n",
        "        return self.input_data\n",
        "\n",
        "    def set_policy(self, N, moves):\n",
        "        policy = np.random.randint(moves, size=(N,))\n",
        "        self.policy = keras.utils.to_categorical(policy)\n",
        "\n",
        "    def get_policy(self):\n",
        "        return self.policy\n",
        "\n",
        "    def set_value(self, N):\n",
        "        value = np.random.randint(2, size=(N,))\n",
        "        self.value = value.astype(\"float32\")\n",
        "\n",
        "    def get_value(self):\n",
        "        return self.value\n",
        "\n",
        "    def set_end(self, N):\n",
        "        end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "        self.end = end.astype(\"float32\")\n",
        "\n",
        "    def get_end(self):\n",
        "        return self.end\n",
        "\n",
        "    def set_groups(self, N):\n",
        "        groups = np.zeros((N, 19, 19, 1))\n",
        "        self.groups = groups.astype(\"float32\")\n",
        "\n",
        "    def get_groups(self):\n",
        "        return self.groups\n",
        "\n",
        "    @abstractmethod\n",
        "    def set_model(self):\n",
        "        pass\n",
        "\n",
        "    def train_model(self, epochs):\n",
        "        for i in range(1, epochs + 1):\n",
        "            print(f\"epoch {str(i)}\")\n",
        "            golois.getBatch(\n",
        "                self.input_data,\n",
        "                self.policy,\n",
        "                self.value,\n",
        "                self.end,\n",
        "                self.groups,\n",
        "                i * self.N,\n",
        "            )\n",
        "            history = self.model.fit(\n",
        "                self.input_data,\n",
        "                {\"policy\": self.policy, \"value\": self.value},\n",
        "                epochs=1,\n",
        "                batch_size=self.batch,\n",
        "            )\n",
        "            # Extraction des valeurs depuis history.history\n",
        "            self.loss_total.append(history.history[\"loss\"][0])  # Loss globale\n",
        "            self.policy_loss.append(history.history[\"policy_loss\"][0])  # Policy loss\n",
        "            self.value_loss.append(history.history[\"value_loss\"][0])  # Value loss\n",
        "            self.policy_acc.append(history.history[\"policy_categorical_accuracy\"][0])  # Policy accuracy\n",
        "            self.value_mse.append(history.history[\"value_mse\"][0])  # Value MSE\n",
        "            if i % 5 == 0:\n",
        "                gc.collect()\n",
        "            if i % 20 == 0:\n",
        "                golois.getValidation(\n",
        "                    self.input_data, self.policy, self.value, self.end\n",
        "                )\n",
        "                val = self.model.evaluate(\n",
        "                    self.input_data,\n",
        "                    [self.policy, self.value],\n",
        "                    verbose=0,\n",
        "                    batch_size=self.batch,\n",
        "                )\n",
        "                print(f\"{val=}\")\n",
        "\n",
        "    def save_model(self, name):\n",
        "        self.model.save(name)\n",
        "        files.download(name)\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Trace les courbes des pertes et métriques en fonction des époques.\"\"\"\n",
        "        epochs = range(1, len(self.loss_total) + 1)  # Liste des époques\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Graphique des pertes\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, self.loss_total, label=\"Loss totale\", marker=\"o\")\n",
        "        plt.plot(epochs, self.policy_loss, label=\"Policy Loss\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_loss, label=\"Value Loss\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur de la perte\")\n",
        "        plt.title(\"Évolution des pertes\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Graphique des métriques\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, self.policy_acc, label=\"Policy Accuracy\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_mse, label=\"Value MSE\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur des métriques\")\n",
        "        plt.title(\"Évolution des métriques\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Affichage\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfuVC90KRFDQ"
      },
      "outputs": [],
      "source": [
        "class GONetDemo(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def set_model(self):\n",
        "        input_ = keras.Input(shape=(19, 19, self.planes), name=\"board\")\n",
        "        x = layers.Conv2D(self.filters, 1, activation=\"relu\", padding=\"same\")(\n",
        "            input_\n",
        "        )\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(\n",
        "                self.filters, 3, activation=\"relu\", padding=\"same\"\n",
        "            )(x)\n",
        "        policy_head = layers.Conv2D(\n",
        "            1,\n",
        "            1,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation(\"softmax\", name=\"policy\")(policy_head)\n",
        "        value_head = layers.Conv2D(\n",
        "            1,\n",
        "            1,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        "        )(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            1,\n",
        "            activation=\"sigmoid\",\n",
        "            name=\"value\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(value_head)\n",
        "\n",
        "        model = keras.Model(inputs=input_, outputs=[policy_head, value_head])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "            loss={\n",
        "                \"policy\": \"categorical_crossentropy\",\n",
        "                \"value\": \"binary_crossentropy\",\n",
        "            },\n",
        "            loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "            metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "        )\n",
        "\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CVZ_rb1QVelh",
        "outputId": "6b6f0f2d-a8c1-4a5a-9a11-22f8d358ff37"
      },
      "outputs": [],
      "source": [
        "GONetDemo_instance = GONetDemo()\n",
        "GONetDemo_instance.set_model()\n",
        "GONetDemo_instance.train_model(20)\n",
        "GONetDemo_instance.plot_training_history()\n",
        "# GONet_instance.save_model(\"test.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqGFjAejB2sH"
      },
      "outputs": [],
      "source": [
        "class GONetResidual(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    # Residual Block Function\n",
        "    def residual_block(self, x, filters):\n",
        "        \"\"\"A ResNet-style residual block with skip connection.\"\"\"\n",
        "        shortcut = x  # Save input for shortcut connection\n",
        "\n",
        "        x = layers.Conv2D(\n",
        "            filters,\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Add()([x, shortcut])  # Add residual connection\n",
        "        x = layers.ReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_model(self):\n",
        "        input_layer = layers.Input(shape=(19, 19, self.planes), name=\"board\")\n",
        "        # Initial Conv Layer\n",
        "        x = layers.Conv2D(\n",
        "            self.filters,\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(input_layer)\n",
        "        # Apply 2 Residual Blocks\n",
        "        for _ in range(2):\n",
        "            x = self.residual_block(x, self.filters)\n",
        "\n",
        "        # Policy Head (Move Probabilities)\n",
        "        policy_head = layers.Conv2D(\n",
        "            2,\n",
        "            (1, 1),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Dense(\n",
        "            361,\n",
        "            activation=\"softmax\",\n",
        "            name=\"policy\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(policy_head)\n",
        "\n",
        "        # Value Head (Win Probability)\n",
        "        value_head = layers.Conv2D(\n",
        "            1,\n",
        "            (1, 1),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        "        )(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            1,\n",
        "            activation=\"sigmoid\",\n",
        "            name=\"value\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(value_head)\n",
        "\n",
        "        # Create Model\n",
        "        model = keras.Model(\n",
        "            inputs=input_layer, outputs=[policy_head, value_head]\n",
        "        )\n",
        "        model.summary()\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "            loss={\n",
        "                \"policy\": \"categorical_crossentropy\",\n",
        "                \"value\": \"binary_crossentropy\",\n",
        "            },\n",
        "            loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "            metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "        )\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D8IbBVJtEj-_",
        "outputId": "2a102004-d125-493d-a1a6-3c4a9f16fb30"
      },
      "outputs": [],
      "source": [
        "GONetResidual_instance = GONetResidual()\n",
        "GONetResidual_instance.set_model()\n",
        "GONetResidual_instance.train_model(20)\n",
        "GONetResidual_instance.plot_training_history()\n",
        "# GONetResidual_instance.save_model(\"test.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GONetMonteCarlo(GONet):\n",
        "\n",
        "    def set_model(self):\n",
        "        \"\"\"Defines the neural network model for Monte Carlo Tree Search.\"\"\"\n",
        "\n",
        "        input_layer = layers.Input(shape=(19, 19, self.planes))\n",
        "\n",
        "        # Convolutional layers to extract spatial features\n",
        "        x = layers.Conv2D(self.filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(input_layer)\n",
        "        x = layers.Conv2D(self.filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "        x = layers.Conv2D(self.filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "        # Monte Carlo Dropout (Bayesian Approximation)\n",
        "        x = layers.Dropout(0.2)(x, training=True)  # MC Dropout applied at inference\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = layers.Flatten()(x)\n",
        "\n",
        "        # Policy Head\n",
        "        policy_hidden = layers.Dense(128, activation=\"relu\")(x)\n",
        "        policy_hidden = layers.Dropout(0.2)(policy_hidden, training=True)  # Monte Carlo Dropout\n",
        "        policy_output = layers.Dense(self.moves, activation=\"softmax\", name=\"policy\")(policy_hidden)\n",
        "\n",
        "        # Value Head\n",
        "        value_hidden = layers.Dense(128, activation=\"relu\")(x)\n",
        "        value_hidden = layers.Dropout(0.2)(value_hidden, training=True)  # Monte Carlo Dropout\n",
        "        value_output = layers.Dense(1, activation=\"tanh\", name=\"value\")(value_hidden)\n",
        "\n",
        "        # Create Model\n",
        "        self.model = keras.Model(inputs=input_layer, outputs=[policy_output, value_output])\n",
        "\n",
        "        # Compile Model\n",
        "        self.model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss={\"policy\": \"categorical_crossentropy\", \"value\": \"mean_squared_error\"},\n",
        "            metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "        )\n",
        "\n",
        "        self.model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GONetMonteCarlo_instance = GONetMonteCarlo()\n",
        "GONetMonteCarlo_instance.set_model()\n",
        "GONetMonteCarlo_instance.train_model(20)\n",
        "GONetMonteCarlo_instance.plot_training_history()\n",
        "# GONetResidual_instance.save_model(\"test.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
